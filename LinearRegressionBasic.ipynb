{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP45Wqac4SirSWfdVWqvGtp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarkersaadahmed/Data-Science-ROADMAP/blob/main/LinearRegressionBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6NKdz-gjOSl",
        "outputId": "558d0d17-5726-4d62-ae29-a91dc967f327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "1.25.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we are doing our first machine learning program\n",
        "#on linear regressions\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "#first we would have to download the csv file and leave the csf vile in the\n",
        "#program directory but i dont have a laptop charger atm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB9nfAuKjtGJ",
        "outputId": "6c13f1b1-4234-4099-a99b-f9f9d4397725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic linear regression"
      ],
      "metadata": {
        "id": "AZNoBw1EBki6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#linear regression is mostly used to predict a trend in analysis that is based on the given datas. Based on the given datas and the trend that it follows, by the help of linear regression, it will be able to identify the trend and predict future outcomes based on the data"
      ],
      "metadata": {
        "id": "JqugWD3FCRsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "\n",
        "#we downloaded the file and allowed the pc to read the file that is downloaded [used sep method to separate our datas using a given punctuation not so importnat]\n",
        "df = pd.read_csv('data.csv', sep=\";\")\n",
        "#we segregated the headers into column names to ensure a specific column identifies those rows\n",
        "#these are also used to really replace the original column names with the column names\n",
        "#the user has implied\n",
        "df = df[[\"Column1\", \"Column2\", \"Column3\", \"Column4\", \"Column5\"]]\n",
        "#we want to predict whatever the datas or rows that is assigned as column3\n",
        "predict = 'Column3'\n",
        "#we dont want to include the predicted data since\n",
        "#1) we dont want the machine to know what the datas are representing which in this case\n",
        "#can easily guess the next value just by looking at the predicted datas and\n",
        "#2) we want the training and test datas specificically for this predicted column\n",
        "X = df.drop(predict, axis=1)\n",
        "y = df[predict]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "QUvW-XC1Ier0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to understand the BASIC linear regression [NOT ADVANCED]\n",
        "\n",
        "1) import whatever modules you know [main ones are numpy, matplotlib, sklearn , tensorflow and pandas too\n",
        "2) download the file and by using the pandas module, read the file [maybe use separate method to separate the datas]\n",
        "3)  if required replace the original column names with your choice of column names to easily identify what column represents what\n",
        "4) since linear regression is a supervised leraning, we must have the known datas and the unknown datas [which are simply the train datas and test datas respectively]\n",
        "5) pick a specific column name that you want to predict\n",
        "6) from point 5 ensure that you drop the predicted column and on one axis import that as the predicted value and on the other, all the other values\n",
        "that way you are able to predict the unknown values based on the given known values\n",
        "7) split the values into train data values and test data values for known and unkown. test_size to indicate the percentage of test values and train values"
      ],
      "metadata": {
        "id": "irck4i83KtJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#linear regression is mostly used when there is an observed trend [house price for example] that never stays perfect, it changes, linear regression is used on those times"
      ],
      "metadata": {
        "id": "ZaWwkTcdNSkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#equation of a linear regression is denoted by y = mx + b\n",
        "#m = (y2 - y1) / (x2 - x1) #gradient denoted\n",
        "#b = y1 - m * x1 #y intercept denoted\n"
      ],
      "metadata": {
        "id": "tnZ4Dy-PNag3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in linear regression, a predicted value will output based on the equation y = mx + b.....LETS say for example x is the value you know [assume its 17 someones grade] so that student got 17 / 20 [good stuff] now we know our X, that is 17 now lets say out m gradient was 0.71, our b value was 0.63. Based on the equation y = mx + b, you plot the x value, plot the b value, plot the m value and find the y value, which is the predicted value. That is how a machine will predict your final output [THIS IS WHY IT IS CALLED SUPERVISED LEARNING]"
      ],
      "metadata": {
        "id": "iCP7fereOUic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "\n",
        "#we downloaded the file and allowed the pc to read the file that is downloaded [used sep method to separate our datas using a given punctuation not so importnat]\n",
        "df = pd.read_csv('data.csv', sep=\";\")\n",
        "#we segregated the headers into column names to ensure a specific column identifies those rows\n",
        "#these are also used to really replace the original column names with the column names\n",
        "#the user has implied\n",
        "df = df[[\"Column1\", \"Column2\", \"Column3\", \"Column4\", \"Column5\"]]\n",
        "#we want to predict whatever the datas or rows that is assigned as column3\n",
        "predict = 'Column3'\n",
        "#we dont want to include the predicted data since\n",
        "#1) we dont want the machine to know what the datas are representing which in this case\n",
        "#can easily guess the next value just by looking at the predicted datas and\n",
        "#2) we want the training and test datas specificically for this predicted column\n",
        "X = df.drop(predict, axis=1)\n",
        "y = df[predict]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "#this is where we will draw the graph use the linear equation\n",
        "linear = LinearRegression() #drawn the graph JUST DRAWN THE GRAPH THERE IS NO INPUT\n",
        "linear.fit(X_train, y_train) #these are my input values\n",
        "#these are my trained datas, the datas i already know off. The linear graph will be drawn\n",
        "#and the known points [the datas i know already] will be plotted not the\n",
        "#ones I am supposed to know of\n",
        "acc = linear.score(x_test, y_test)\n",
        "#on the linear fit, my linear graph alongside my known trained values are plotted all good\n",
        "#on the acc [stands for accuracy] I will compare the datas from the train data\n",
        "#and test data and find the accuracy [using linear.score] between train and test\n",
        "\n",
        "print(acc)\n",
        "#simply print the accuracy\n",
        "print(linear.coef_)\n",
        "#print the gradient for each dimension [as in each column]\n",
        "print(linear.intercept_)\n",
        "#print the y intercept [the part b in y = mx + b]\n",
        "predictions - linear.predict(x_test)\n",
        "#assinging a predicted axis\n",
        "for x in range(len(predcitions)):\n",
        "  #iterating through every data values from the column x_test\n",
        "    print(predictions[x], y_test[x]) #we get the predicted values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "rcNTn_nUO24G",
        "outputId": "89bafeec-2269-497e-a334-cb093ab052c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-14990e8157e0>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#we downloaded the file and allowed the pc to read the file that is downloaded [used sep method to separate our datas using a given punctuation not so importnat]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#we segregated the headers into column names to ensure a specific column identifies those rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#these are also used to really replace the original column names with the column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SAVING MODELS AND PLOTTING DATA USING PICKLE"
      ],
      "metadata": {
        "id": "-BT0dXXlTJdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from matplotlib import style\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "#we downloaded the file and allowed the pc to read the file that is downloaded [used sep method to separate our datas using a given punctuation not so importnat]\n",
        "df = pd.read_csv('data.csv', sep=\";\")\n",
        "#we segregated the headers into column names to ensure a specific column identifies those rows\n",
        "#these are also used to really replace the original column names with the column names\n",
        "#the user has implied\n",
        "df = df[[\"Column1\", \"Column2\", \"Column3\", \"Column4\", \"Column5\"]]\n",
        "#we want to predict whatever the datas or rows that is assigned as column3\n",
        "predict = 'Column3'\n",
        "#we dont want to include the predicted data since\n",
        "#1) we dont want the machine to know what the datas are representing which in this case\n",
        "#can easily guess the next value just by looking at the predicted datas and\n",
        "#2) we want the training and test datas specificically for this predicted column\n",
        "X = df.drop(predict, axis=1)\n",
        "y = df[predict]\n",
        "best = 0\n",
        "for element in range(30):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  #this is where we will draw the graph use the linear equation\n",
        "  linear = LinearRegression() #drawn the graph JUST DRAWN THE GRAPH THERE IS NO INPUT\n",
        "  linear.fit(X_train, y_train) #these are my input values\n",
        "  #these are my trained datas, the datas i already know off. The linear graph will be drawn\n",
        "  #and the known points [the datas i know already] will be plotted not the\n",
        "  #ones I am supposed to know of\n",
        "  acc = linear.score(x_test, y_test)\n",
        "  #on the linear fit, my linear graph alongside my known trained values are plotted all good\n",
        "  #on the acc [stands for accuracy] I will compare the datas from the train data\n",
        "  #and test data and find the accuracy [using linear.score] between train and test\n",
        "  if acc > best:\n",
        "    best = acc\n",
        "    with open('filename.pickle', 'wb') as f:\n",
        "      pickle.dump(linear, f)\n",
        "\n",
        "print(acc)\n",
        "#simply print the accuracy\n",
        "\n",
        "with open(filename.picke, 'wb') as f:\n",
        "  pickle.dump(linear, f)\n",
        "#we created a writable binary file,\n",
        "#convert WHATEVER THE TEXT WE ARE GOING TO IMPORT AND\n",
        "#convert into the bite stream and save that bitestream file into our file f\n",
        "#DUMP IS USED TO SAVE THE FILE\n",
        "pickle_in = open(\"filename.pickle\", 'rb')\n",
        "linear = pickle.load(pickle_in)\n",
        "#so rather tha manually writing out the X_train and Y_train\n",
        "#we simply create file using the name and wb\n",
        "#convert the file into a binary file\n",
        "#dump [as in store] the file\n",
        "#open the file as a readable binary file\n",
        "#use a linear module to call the data stored in the file\n",
        "\n",
        "print(linear.coef_)\n",
        "#print the gradient for each dimension [as in each column]\n",
        "print(linear.intercept_)\n",
        "#print the y intercept [the part b in y = mx + b]\n",
        "predictions - linear.predict(x_test)\n",
        "#assinging a predicted axis\n",
        "for x in range(len(predcitions)):\n",
        "  #iterating through every data values from the column x_test\n",
        "    print(predictions[x], y_test[x]) #we get the predicted values\n",
        "\n",
        "p = \"Column1\"\n",
        "style.use('ggplot')\n",
        "plt.scatter(X_test[p], y_test, color='black')\n",
        "plt.plot(X_test[p], predictions, color='blue', linewidth=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JI1FhmxeTL9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#we created a writable binary file,\n",
        "#convert WHATEVER THE TEXT WE ARE GOING TO IMPORT AND\n",
        "#convert into the bite stream and save that bitestream file into our file f\n",
        "#DUMP IS USED TO SAVE THE FILE"
      ],
      "metadata": {
        "id": "IIv22Y9aV18P"
      }
    }
  ]
}